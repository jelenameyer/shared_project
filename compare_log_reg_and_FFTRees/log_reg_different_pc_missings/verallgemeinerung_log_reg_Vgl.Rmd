---
title: "all_data_alg_comparison"
author: "Jelena Meyer and Hansjörg Neth"
date: "2023-11-15"
output: html_document
---

```{r}
require(stats)
require(FFTrees)
require(mice)
library(dplyr)
```

```{r}
# here all concrete dataset definitions
data <- heartdisease
# criterion muss einmal mit strg f komplett im ganzen doc ersetzt werden!
# nachdem significant predictors gefunden, händisch umtragen!
# data_subset_cca <- select(data_fit, cp, ca, trestbps, oldpeak, diagnosis)
# baseline: 
baseline <- 0.51
# Preparations:
pc <- 0.2
```




# standardise data, because some algorithms perform better with standardised data (to be fair for those)
```{r}
data <- as.data.frame(lapply(data, function(x) {
  if(is.numeric(x)) scale(x) else x
}))
```


# divide data into 50% train and test data:
```{r}
nrow(data)

# set seed for reproducability
set.seed(13)

# take 50% of rows of df and build fitting df
data_fit_indices <- sample(nrow(data), 0.5 * nrow(data), replace = FALSE)
data_fit <- data[data_fit_indices,]
nrow(data_fit)


# find remaining rows and put into predicting df
data_predict_indices <- setdiff(1:nrow(data), data_fit_indices)
data_predict <- data[data_predict_indices,]
nrow(data_predict)
number_cases_to_predict <- nrow(data_predict)
```




# build regression algorithm with fitting dataset:

```{r}
model <- glm(diagnosis ~ ., data=data_fit, family="binomial")
```

# get accuracy statistic

# see how good log reg is with fitted data:

```{r}
# build algorithm:
reg_log <- predict(model, data_fit, type = 'response')
class_pred <- ifelse(reg_log > 0.5, 1, 0)

# get confusion matrix
confusion_matrix <- table(Predicted = class_pred, Actual = data_fit$diagnosis)
print(confusion_matrix)
# calculate accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(accuracy)
```
# see how good log reg predicts new data

```{r}
# build algorithm:
reg_log <- predict(model, data_predict, type = 'response')
class_pred <- ifelse(reg_log > 0.5, 1, 0)

# get confusion matrix
confusion_matrix <- table(Predicted = class_pred, Actual = data_predict$diagnosis)
print(confusion_matrix)
# calculate accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(accuracy)
```


# preparations for listwise deletion in subset data
```{r}
summary(model) # we see that only variables: cp, ca are significant predictors, therefore build subset with only these and criterion + almost significant predictors

# fitting data
data_subset_cca <- select(data_fit, cp, ca, trestbps, oldpeak, diagnosis)

# prediction data
data_subset_cca_predict <- select(data_predict, cp, ca, trestbps, oldpeak, diagnosis)


# fit logistic regression model and compare performance
model_subset_cca <- glm(diagnosis ~ ., data=data_subset_cca, family="binomial")

# build algorithm:
reg_log <- predict(model_subset_cca, data_subset_cca, type = 'response')
class_pred <- ifelse(reg_log > 0.5, 1, 0)

# get confusion matrix
confusion_matrix <- table(Predicted = class_pred, Actual = data_subset_cca$diagnosis)
print(confusion_matrix)
# calculate accuracy for train data
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(accuracy)


# see how well for test data
# build algorithm:
reg_log <- predict(model_subset_cca, data_predict, type = 'response')
class_pred <- ifelse(reg_log > 0.5, 1, 0)

# get confusion matrix
confusion_matrix <- table(Predicted = class_pred, Actual = data_predict$diagnosis)
print(confusion_matrix)
# calculate accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(accuracy)
```




# add missing data (use methods that have been built before)

```{r}
## therefore include function that adds NAs in dataset:
### Define Loop functions (for multiple simulations): ----
replace_values <- function(data, cols, amount, replacement = NA, levels_amount = NULL) {


    # Verify inputs ----
    testthat::expect_true(is.data.frame(data), info = "Data should be a dataframe.") # check that data is a data frame.
    testthat::expect_true(all(cols %in% names(data)), info = "All column names should be present in the data.") # check that columns is/are all variables in the data frame.
    testthat::expect_true(length(cols) == length(amount), info = "Number of columns and percentages have to match.") # check if columns and percentages are of the same length.
    testthat::expect_true(all(is.numeric(amount) & (amount >= 0) ), info = "All amounts should be numeric values.") # check that percentages are all numbers between 0 and 1, or higher (than treat as number of to be replaced values.
    testthat::expect_true(is.character(replacement) | is.numeric(replacement) | is.logical(replacement) | is.na(replacement), info = "Replacement value should be of a valid data type (character, nummeric, logical or NA).") # check that replacement is a valid data type.
    testthat::expect_true(is.null(levels_amount) | is.list(levels_amount), info = "levels_amount should be a list") # check that levels_amount is a list if it's not NULL.
    if (!is.null(levels_amount)) {
      testthat::expect_true(all(names(levels_amount) %in% cols), info = "All names in levels_amount have to correspond to a column in the data.") # check if all elements in levels_amount correspond to a column in the data frame.
      for (col in names(levels_amount)) {
        if (is.factor(data[[col]])) {
          testthat::expect_true(all(names(levels_amount[[col]]) %in% levels(data[[col]])), info = "All levels in levels_amount have to be present in the corresponding column of the data.") # check if all sub-elements in each element are valid levels in the corresponding factor variable.

        }

        else if (is.character(data[[col]])) {
          testthat::expect_true(all(names(levels_amount[[col]]) %in% unique(data[[col]])), info = "All levels in levels_amount have to be present in the corresponding column of the data.")

        }

      }

    }
    # main: ----

    # loop function over all columns that are inserted in form of a vector and corresponding percentages:
    for (i in seq_along(cols)) {

      col <- cols[i]
      perc <- amount[i]


      # Check if the specific column is a factor and has levels_amount defined:
      if (is.factor(data[[col]]) || is.character(data[[col]]) && !is.null(levels_amount) && col %in% names(levels_amount)) {

        # if all these conditions apply for the column, code is executed:
        # get list of different replacement percentages of levels in column:
        lev_amount <- levels_amount[[col]]

        # loop over levels in current column:
        for (cat in names(lev_amount)) {

          # get replacement percentage for current category:
          replace_perc <- lev_amount[[cat]]

          # get rows in column for current category:
          rows <- which(data[[col]] == cat)

          # Calculate how many values should be replaced in category:
          num_replace <-  ifelse(replace_perc <= 1, round(replace_perc * length(rows), 0), replace_perc)

          # Use sample to replace specified percentage of category with replacement input:
          replace_rows <- sample(rows, size = num_replace[1],  replace = FALSE)
          data[replace_rows, col] <- replacement

        }

      } else {

        # Calculate how many values should be replaced:
        num_values <- nrow(data)
        num_replace <-  ifelse(amount <= 1, round(amount * num_values, 0), amount)

        # Use sample to replace specified percentage with replacement input:
        replace_rows <- sample(1:num_values,size = num_replace[1],  replace = FALSE)
        data[replace_rows, col] <- replacement

      }

    }

    # Output: ----

    return(data) # as data frame.

  } # replace_values().
```

```{r}

# get all names of variables but exclude criterion: 
column_names_data <- colnames(data_fit)
column_names_data <- column_names_data[column_names_data != 'diagnosis']

# in total xx% should be NAs in the end, split equally over all variables: 
num_columns <- length(column_names_data)
pc_per_row <- pc

# create vector with that pc for number of rows:
pc_vector <- rep(pc_per_row, times = num_columns)

# set seed for being able to replicate results:
set.seed(139)

# apply replace_values function and thereby create new data frame:
data_NA <- replace_values(data = data_predict, cols = column_names_data, amount = pc_vector)
#data_NA
```



# apply LISTWISE DELETION

```{r}
# add missings in data with only significant predictors (so to not delete to many data)
data_subset_cca <- select(data_fit, cp, ca, trestbps, oldpeak, diagnosis)
# get all names of variables but exclude criterion: 
column_names_data <- colnames(data_subset_cca_predict)
column_names_data <- column_names_data[column_names_data != 'diagnosis']

# in total xx% should be NAs in the end, split equally over all variables: 
num_columns <- length(column_names_data)
pc_per_row <- pc

# create vector with that pc for number of rows:
pc_vector <- rep(pc_per_row, times = num_columns)

# set seed for being able to replicate results:
set.seed(139)

# apply replace_values function and thereby create new data frame:
data_NA_subset_cca <- replace_values(data = data_subset_cca_predict, cols = column_names_data, amount = pc_vector)



```


```{r}
# first alternative: LISTWISE DELETION
# predict NA data with old model, LISTWISE DELETION is default anyway
reg_log_NA <- predict(model_subset_cca, data_NA_subset_cca, type = 'response')
class_pred_NA <- ifelse(reg_log_NA > 0.5, 1, 0)
class_pred_NA
# get confusion matrix
confusion_matrix_NA <- table(Predicted = class_pred_NA, Actual = data_subset_cca_predict$diagnosis)
print(confusion_matrix_NA)
# calculate accuracy
accuracy_NA <- sum(diag(confusion_matrix_NA)) / sum(confusion_matrix_NA)
print(accuracy_NA) 

```


```{r}
# accuracy calculation:
# we take accuracy times percent of classified cases plus baseline accuracy times percent of not classified cases
sum_classified_cases <- confusion_matrix_NA[1,1] + confusion_matrix_NA[1,2] + confusion_matrix_NA[2,1] + confusion_matrix_NA[2,2]
sum_classified_cases
sum_NOT_classified_cases <- number_cases_to_predict - sum_classified_cases
sum_NOT_classified_cases

baseline
accuracy_NA

# calculate accuracy
((sum_classified_cases * accuracy_NA) + (sum_NOT_classified_cases * baseline))/number_cases_to_predict


```

# alternatively with original dataset:

```{r}
# first alternative: LISTWISE DELETION

# predict NA data with old model
reg_log_NA <- predict(model, data_NA, type = 'response')
class_pred_NA <- ifelse(reg_log_NA > 0.5, 1, 0)
class_pred_NA
# get confusion matrix
confusion_matrix_NA <- table(Predicted = class_pred_NA, Actual = data_predict$diagnosis)
print(confusion_matrix_NA)
# calculate accuracy
accuracy_NA <- sum(diag(confusion_matrix_NA)) / sum(confusion_matrix_NA)
print(accuracy_NA) # so gehts nicht einfach, weill dann einfach nur alle NAs rausgeschmissen und nicht mehr vorhergesagt werden!



# accuracy calculation:
# we take accuracy times percent of classified cases plus baseline accuracy times percent of not classified cases
sum_classified_cases <- confusion_matrix_NA[1,1] + confusion_matrix_NA[1,2] + confusion_matrix_NA[2,1] + confusion_matrix_NA[2,2]
sum_classified_cases
sum_NOT_classified_cases <- number_cases_to_predict - sum_classified_cases
sum_NOT_classified_cases
# baseline: 
baseline <- 0.51
baseline
accuracy_NA
# calculate accuracy
((sum_classified_cases * accuracy_NA) + (sum_NOT_classified_cases * baseline))/number_cases_to_predict

```



# median imputation technique

```{r}

# Replace NA values with the median of each column
data_median_imputed <- as.data.frame(lapply(data_NA, function(x) {
  if(is.numeric(x)) {
    return(ifelse(is.na(x), median(x, na.rm = TRUE), x))
  } else {
    return(x)
  }
}))

# Replace NA values in categorical columns with the mode
data_median_imputed <- as.data.frame(lapply(data_median_imputed, function(x) {
  if(is.factor(x) || is.character(x)) {
    mode_value <- names(sort(table(x), decreasing = TRUE))[1]
    return(ifelse(is.na(x), mode_value, x))
  } else {
    return(x)
  }
}))

# predict NA data with median imputed model
reg_log_NA <- predict(model, data_median_imputed, type = 'response')
class_pred_NA <- ifelse(reg_log_NA > 0.5, 1, 0)

# get confusion matrix
confusion_matrix_NA <- table(Predicted = class_pred_NA, Actual = data_predict$diagnosis)
print(confusion_matrix_NA)
# calculate accuracy
accuracy_NA <- sum(diag(confusion_matrix_NA)) / sum(confusion_matrix_NA)
print(accuracy_NA) 
#data_median_imputed
```

# imputation
```{r}
# prepare pc
pc_100 <- pc*100 
pc_100
```



# prepare data (so that criterion is not used in imputation)
```{r}
# remove criterion from data frame with missings, save under new name
original_diagnosis <- data_NA$diagnosis
data_NA_without_crit <- data_NA
data_NA_without_crit$diagnosis <- NULL
#data_NA_without_crit
```


```{r}
# convert character variables into factor
data_NA_without_crit <- data.frame(lapply(data_NA_without_crit, function(x) if(is.character(x)) as.factor(x) else x))
#str(data_NA) 
```


```{r}


# Multiple Imputation with the mice package
imp.data <- mice (data = data_NA_without_crit, m = pc_100 , maxit = 10, seed = 123, print=FALSE)

# Checking if convergence was achieved
#plot(imp.data)


```


# get accuracy performance!

```{r}
# Apply the logistic regression model to each imputed data set
predictions <- lapply(1:pc_100, function(m) {
  dataset <- complete(imp.data, m)
  dataset$diagnosis <- original_diagnosis
  predict(glm(diagnosis ~., family = "binomial", data = dataset), type = "response")
})

# Average the predictions
avg_predictions <- Reduce("+", predictions) / pc_100

# Create binary classification
class_pred_imputed <- ifelse(avg_predictions > 0.5, 1, 0)

# create confusion matrix
confusion_matrix_imputed <- table(Predicted = class_pred_imputed, Actual = data_predict$diagnosis)
print(confusion_matrix_imputed)

# Calculate accuracy
accuracy_imputed <- sum(diag(confusion_matrix_imputed)) / sum(confusion_matrix_imputed)
print(accuracy_imputed)

```





# compare performance of best log reg NA handling method on different NA percentages with the performance of other algorithms

```{r}
# without NAs, baseline performance for train data:

# build best tree. (standard function)
data.fft <- FFTrees(formula = diagnosis ~.,
                           data = data_fit,
                           goal = "acc",
                           goal.chase = "acc",
                           goal.threshold = "acc",
                           decision.labels = c("True", "False"))


# Report on NA cases: 
tree_level_outcome_vars <- c(1:3, 7:12, 25:30)
data.fft$trees$level_stats$train[ , tree_level_outcome_vars]
  
plot(data.fft, data = "train")
```



```{r}
# without NAs, baseline performance for test data:
# build best tree. (standard function)
data.fft <- FFTrees(formula = diagnosis ~.,
                           data = data_fit,
                           data.test =  data_predict,
                           goal = "acc",
                           goal.chase = "acc",
                           goal.threshold = "acc",
                           decision.labels = c("True", "False"))


# Report on NA cases: 
tree_level_outcome_vars <- c(1:3, 7:12, 25:30)
data.fft$trees$level_stats$test[ , tree_level_outcome_vars]
  
plot(data.fft, data = "test")
```


```{r}
# build best tree. xx% NAs (standard function)
data.fft_NA <- FFTrees(formula = diagnosis ~.,
                           data = data_fit,
                           data.test =  data_NA,
                           goal = "acc",
                           goal.chase = "acc",
                           goal.threshold = "acc",
                           decision.labels = c("True", "False"))


# Report on NA cases: 
tree_level_outcome_vars <- c(1:3, 7:12, 25:30)
data.fft_NA$trees$level_stats$train[ , tree_level_outcome_vars]
  
plot(data.fft_NA, data = "test")
```

# Vergleich funktioniert nicht richtig, da die Umwandlung aller Variable in nummerical die Baseline performance sehr stark verschlechtert. 
```{r}

# Creating a single imputed dataset
long_data <- complete(imp.data, "long")
# Calculate the mean of imputed values for each variable
aggregated_data <- aggregate(. ~ .imp + .id, data = long_data, FUN = mean)

# remove .imp and .id columns to get the final dataset
final_imputed_data <- aggregated_data[, !(names(aggregated_data) %in% c(".imp", ".id"))]

# change data_fit to same types variables as imputed data
data_fit_types_dif <- data.frame(lapply(data_fit, function(x) if(is.character(x)) as.numeric(x) else x))

# add criterion to imputed data
final_imputed_data$diagnosis <- original_diagnosis

# convert  criterion back into logical
final_imputed_data$diagnosis <- as.logical(final_imputed_data$diagnosis == 1)
data_fit_types_dif$diagnosis <- as.logical(data_fit_types_dif$diagnosis == 1)


# Using the final imputed data to train FFTrees
data.fft <- FFTrees(formula = diagnosis ~ .,
                     data = data_fit_types_dif,
                     data.test = data_fit_types_dif,
                     goal = "acc",
                     goal.chase = "acc",
                     goal.threshold = "acc",
                     main = "data Disease",
                     decision.labels = c("True", "False"))

print(data.fft)
plot(data.fft, data = "test")
str(final_imputed_data)
str(data_fit_types_dif)

```





